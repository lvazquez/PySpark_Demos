{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afde006",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "hostname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6e59b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as skl\n",
    "\n",
    "print(\"PATH: {}\".format(os.environ['PATH']))\n",
    "print(\"PYTHONPATH: {}\".format(os.environ['PYTHONPATH']))\n",
    "print(\"\")\n",
    "print(\"Spark: {}\".format(spark.version))\n",
    "print(\"Python: {}\".format(sys.version))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f814f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2314d5",
   "metadata": {},
   "source": [
    "## Ejemplo Spark RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4eba7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [(1,\"One\"), (2,\"Two\"), (3, \"Three\"), (4, \"Four\"), (5, \"Five\")]\n",
    "rdd = sc.parallelize(data)\n",
    "def add_pair(a,b):\n",
    "    p0 = a[0] + b[0]\n",
    "    p1 = \"{}:{}\".format(a[1],b[1])\n",
    "    return (p0,p1)\n",
    "print(rdd.reduce(add_pair))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b280b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = rdd.toDF([\"number\", \"text\"])\n",
    "df.limit(3).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8913f7",
   "metadata": {},
   "source": [
    "## Ejemplo Read Spark DataFrame & Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4377a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "house_dom = spark.sparkContext.textFile(\"/data/CaliforniaHousing/cal_housing.domain\")\\\n",
    "    .map(lambda s: s.split(':')[0])\n",
    "columns = house_dom.collect()\n",
    "\n",
    "house_data = spark.read.csv(\"/data/CaliforniaHousing/cal_housing.data\", inferSchema=True)\\\n",
    "    .toDF(*columns)\n",
    "house_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c93e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "house_data.toPandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af27e2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py3Spark2",
   "language": "python",
   "name": "py3spark2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
